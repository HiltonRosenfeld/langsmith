{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangSmith Tracing via the REST API\n",
    "\n",
    "LangSmith tracing is built on \"runs\", which are analogous to traces and spans in OpenTelemetry.\n",
    "\n",
    "If you aren't using a language supported by one of the LangSmith SDK's (python and JS/TS), then the only way to log chain and LLM runs to LangSmith is via this REST API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "A valid API key created in the LangSmith app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "LANGSMITH_API_KEY = os.environ.get(\"LANGSMITH_API_KEY\")\n",
    "LANGCHAIN_ENDPOINT = \"https://api.smith.langchain.com\"\n",
    "project_name = \"default\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Basics - Logging a Run\n",
    "Each run represents the start and end of a function call, so we typically log the run in two calls, one to create the run and a second to end the run.\n",
    "\n",
    "Events can be used to log additional minor information about what occurred during a run when that information doesn't merit an entire child run and is not the final output of the run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Create the Run**\n",
    "\n",
    "Create the run by submitting a POST request at the beginning of the function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import uuid\n",
    "\n",
    "import requests\n",
    "\n",
    "run_id = str(uuid.uuid4())\n",
    "\n",
    "res = requests.post(\n",
    "    f\"{LANGCHAIN_ENDPOINT}/runs\",\n",
    "    json={\n",
    "        \"id\": run_id,\n",
    "        \"name\": \"MyFirstRun\",\n",
    "        \"run_type\": \"chain\",\n",
    "        \"start_time\": datetime.datetime.utcnow().isoformat(),\n",
    "        \"inputs\": {\"text\": \"Foo\"},\n",
    "        \"tags\": [\"langsmith\", \"rest\", \"my-example\"],\n",
    "    },\n",
    "    headers={\"x-api-key\": LANGSMITH_API_KEY},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add events**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = []\n",
    "events.append({\"event_name\": \"retry\", \"reason\": \"never gonna give you up\"})\n",
    "events.append({\"event_name\": \"new_token\", \"value\": \"foo\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Update the Run**\n",
    "\n",
    "Update the run via a PATCH request at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.patch(\n",
    "    f\"{LANGCHAIN_ENDPOINT}/runs/{run_id}\",\n",
    "    json={\n",
    "        \"outputs\": {\"my_output\": \"Bar\"},\n",
    "        \"end_time\": datetime.datetime.utcnow().isoformat(),\n",
    "        \"events\": events,\n",
    "    },\n",
    "    headers={\"x-api-key\": LANGSMITH_API_KEY},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging an LLM Run\n",
    "\n",
    "Correctly formatted runs with the run_type of \"llm\" let you:\n",
    "\n",
    "- Track token usage\n",
    "- Render \"prettier\" chat or completion message formats for better readability.\n",
    "\n",
    "LangSmith supports OpenAI's llm message schema, so you can directly log the inputs and outputs of your call to any openai-compatible API without having to convert it to a new format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logging LLM Chat Messages**\n",
    "\n",
    "LangSmith expects the following format:\n",
    "\n",
    "- Provide messages: [{\"role\": string, \"content\": string}] as a key-value pair in the inputs\n",
    "- Provide choices: [{\"message\": {\"role\": string, \"content\": string}] as a key-value pair in the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = str(uuid.uuid4())\n",
    "\n",
    "res = requests.post(\n",
    "    f\"{LANGCHAIN_ENDPOINT}/runs\",\n",
    "    json={\n",
    "        \"id\": run_id,\n",
    "        \"name\": \"MyChatModelRun\",\n",
    "        \"run_type\": \"llm\",\n",
    "        \"inputs\": {\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": \"What's the weather in SF like?\"}],\n",
    "            # Optional\n",
    "            \"model\": \"text-davinci-003\",\n",
    "            \"functions\": [\n",
    "                {\n",
    "                    \"name\": \"get_current_weather\",\n",
    "                    \"description\": \"Get the current weather in a given location\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"location\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                            },\n",
    "                            \"unit\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                            },\n",
    "                        },\n",
    "                        \"required\": [\"location\"],\n",
    "                    },\n",
    "                }\n",
    "            ],\n",
    "            # You can add other invocation paramers as k-v pairs\n",
    "            \"temperature\": 0.0,\n",
    "        },\n",
    "        \"start_time\": datetime.datetime.utcnow().isoformat(),\n",
    "        \"session_name\": project_name,\n",
    "    },\n",
    "    headers={\"x-api-key\": LANGSMITH_API_KEY},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.patch(\n",
    "    f\"{LANGCHAIN_ENDPOINT}/runs/{run_id}\",\n",
    "    json={\n",
    "        \"end_time\": datetime.datetime.utcnow().isoformat(),\n",
    "        \"outputs\": {\n",
    "            \"choices\": [\n",
    "                {\n",
    "                    \"index\": 0,\n",
    "                    \"message\": {\n",
    "                        \"role\": \"assistant\",\n",
    "                        # Content is whatever string response the model generates\n",
    "                        \"content\": \"Mostly cloudy.\",\n",
    "                        # Function call is the function invocation and arguments as a string\n",
    "                        \"function_call\": {\n",
    "                            \"name\": \"get_current_weather\",\n",
    "                            \"arguments\": '{\\n\"location\": \"San Francisco, CA\"\\n}',\n",
    "                        },\n",
    "                    },\n",
    "                    \"finish_reason\": \"function_call\",\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "    },\n",
    "    headers={\"x-api-key\": LANGSMITH_API_KEY},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nesting Runs\n",
    "\n",
    "We can embed the nesting associations within the log, making it much easier to debug complex chains.\n",
    "\n",
    "- Include a parent_run_id in your JSON body.\n",
    "- Track the execution_order of the child run for it to be rendered correctly in the trace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RunLogger**\n",
    "\n",
    "Create a new RunLogger class that manages the execution order state for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "class RunLogger:\n",
    "    def post_run(\n",
    "        self, data: dict, name: str, run_id: str, parent_run_id: Optional[str] = None\n",
    "    ) -> None:\n",
    "        requests.post(\n",
    "            f\"{LANGCHAIN_ENDPOINT}/runs\",\n",
    "            json={\n",
    "                \"id\": run_id,\n",
    "                \"name\": name,\n",
    "                \"run_type\": \"chain\",\n",
    "                \"parent_run_id\": parent_run_id,\n",
    "                \"inputs\": data,\n",
    "                \"start_time\": datetime.datetime.utcnow().isoformat(),\n",
    "                \"session_name\": project_name,\n",
    "            },\n",
    "            headers={\"x-api-key\": LANGSMITH_API_KEY},\n",
    "        )\n",
    "\n",
    "    def patch_run(\n",
    "        self, run_id: str, output: Optional[dict] = None, error: Optional[str] = None\n",
    "    ) -> None:\n",
    "        requests.patch(\n",
    "            f\"{LANGCHAIN_ENDPOINT}/runs/{run_id}\",\n",
    "            json={\n",
    "                \"error\": error,\n",
    "                \"outputs\": output,\n",
    "                \"end_time\": datetime.datetime.utcnow().isoformat(),\n",
    "            },\n",
    "            headers={\"x-api-key\": LANGSMITH_API_KEY},\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nested Run**\n",
    "\n",
    "Create a simple fibonacci function and log each call as a \"chain\" run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = RunLogger()\n",
    "\n",
    "def fibonacci(n: int, depth: int = 0, parent_run_id: Optional[str] = None) -> int:\n",
    "    run_id = str(uuid.uuid4())\n",
    "    logger.post_run(\n",
    "        {\"n\": n}, f\"fibonacci_recursive\", run_id, parent_run_id=parent_run_id\n",
    "    )\n",
    "    try:\n",
    "        if n <= 1:\n",
    "            result = n\n",
    "        else:\n",
    "            result = fibonacci(n - 1, depth + 1, parent_run_id=run_id) + fibonacci(\n",
    "                n - 2, depth + 1, parent_run_id=run_id\n",
    "            )\n",
    "        logger.patch_run(run_id, output={\"result\": result})\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logger.patch_run(run_id, error=str(e))\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fibonacci(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ragstack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
